--- 
permalink: /W08/ 
--- 
[HOME](../) 

<br>
# Top 10 List of Week 08

1. [Preemptive Scheduling](geeksforgeeks.org/preemptive-and-non-preemptive-scheduling/)<br>
Preemptive scheduling is used when a process switches from running state to ready state or from waiting state to ready state. The resources (mainly CPU cycles) are allocated to the process for the limited amount of time and then is taken away, and the process is again placed back in the ready queue if that process still has CPU burst time remaining. That process stays in ready queue till it gets next chance to execute. 

2. [Non-Preemptive Scheduling](https://www.geeksforgeeks.org/preemptive-and-non-preemptive-scheduling/)<br> 
Non-preemptive Scheduling is used when a process terminates, or a process switches from running to waiting state. In this scheduling, once the resources (CPU cycles) is allocated to a process, the process holds the CPU till it gets terminated or it reaches a waiting state. In case of non-preemptive scheduling does not interrupt a process running CPU in middle of the execution. Instead, it waits till the process complete its CPU burst time and then it can allocate the CPU to another process.

3. [Why do we need scheduling?](https://www.geeksforgeeks.org/cpu-scheduling-in-operating-systems/)<br> 
A typical process involves both I/O time and CPU time. In a uni programming system like MS-DOS, time spent waiting for I/O is wasted and CPU is free during this time. In multi programming systems, one process can use CPU while another is waiting for I/O. This is possible only with process scheduling.

4. [Thread Scheduling](https://www.geeksforgeeks.org/thread-scheduling/)<br>
Scheduling of threads involves two boundary scheduling,
Scheduling of user level threads (ULT) to kernel level threads (KLT) via leightweight process (LWP) by the application developer.
Scheduling of kernel level threads by the system scheduler to perform different unique os functions.

5. [CPU Burst](http://www2.cs.uregina.ca/~hamilton/courses/330/notes/scheduling/scheduling.html)<br> 
CPU burst is the amount of time the process uses the processor before it is no longer ready

6. [Completely Fair Scheduler](https://www.geeksforgeeks.org/completely-fair-scheduler-cfs-and-brain-fuck-scheduler-bfs/)<br> 
It is based on Rotating Staircase Deadline Scheduler (RSDL).
It is default scheduling process since version 2.6.23.
Elegant handling of I/O and CPU bound process.

7. [Asymmetric Multiprocessing vs. Symmetric Multiprocessing (SMP)](https://www.tutorialspoint.com/difference-between-asymmetric-and-symmetric-multiprocessing)<br> 
Asymmetric multiprocessing is the use of two or more processors handled by one master processor. All CPUs are interconnected but are not self-scheduling. AMP is used to schedule specific task to CPU based on priority and importance of task.
Symmetric multiprocessing is the use of two or more self-scheduling processors sharing a common memory space. Each processor has access to I/O and memory devices. SMP applies multiple CPUs to a task to complete in parallel and faster fashion.

8. [Non-Uniform Memory Access](https://whatis.techtarget.com/definition/NUMA-non-uniform-memory-access)<br>
NUMA (non-uniform memory access) is a method of configuring a cluster of microprocessor in a multiprocessing system so that they can share memory locally, improving performance and the ability of the system to be expanded

9. [Load Balancing](https://www.nginx.com/resources/glossary/load-balancing/)<br> 
Load balancing refers to efficiently distributing incoming network traffic across a group of backend servers, also known as a server farm or server pool.

10. [Multicore Processors](https://insights.sei.cmu.edu/sei_blog/2017/08/multicore-processing.html)<br>
A multicore processor is a single integrated circuit (a.k.a., chip multiprocessor or CMP) that contains multiple core processing units, more commonly known as cores. There are many different multicore processor architectures, which vary in terms of
